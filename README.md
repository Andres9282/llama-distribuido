# üß† LLaMA Distribuido

Sistema de inferencia distribuida para el modelo LLaMA 2 usando `torch.distributed` y `accelerate`, coordinado por una orquestadora y ejecutado por m√∫ltiples nodos que comparten el modelo de forma real.

---

## ‚öôÔ∏è Requisitos por nodo

- Python 3.9‚Äì3.11
- Git
- Tailscale (para red privada entre m√°quinas)
- GPU con soporte CUDA
- Token de Hugging Face con acceso a `meta-llama/Llama-2-7b-hf`
- Entorno virtual (`venv`)
- Configuraci√≥n individual de Accelerate

---

## üß≠ Configuraci√≥n por nodo

```bash
# Clonar el repositorio
git clone https://github.com/Andres9282/llama-distribuido.git
cd llama-distribuido

# Crear entorno virtual
python3 -m venv venv
source venv/bin/activate

# Instalar dependencias
pip install torch transformers accelerate
